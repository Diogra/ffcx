
import numpy
import ufl
from ufl import as_vector
from ufl.common import unique_post_traversal
from ufl.classes import (Terminal, FormArgument, Grad, Restricted,
                         Indexed, ComponentTensor, ListTensor, Transposed, Variable,
                         IndexSum, MultiIndex,
                         UtilityType, Label, Data)
from ufl.algorithms.traversal import traverse_terminals
from uflacs.utils.assertions import error
from uflacs.algorithms.indexing import *

from uflacs.algorithms.datastructures import int_array, object_array, CRS, rows_to_crs, rows_dict_to_crs

def count_nodes_with_unique_post_traversal(expr):
    """Yields o for each node o in expr, child before parent. Never visits a node twice."""
    stack = []
    stack.append((expr, list(expr.operands())))
    visited = {}
    while stack:
        expr, ops = stack[-1]
        for i, o in enumerate(ops):
            if o is not None and o not in visited:
                stack.append((o, list(o.operands())))
                ops[i] = None
                break
        else:
            if not isinstance(expr, UtilityType):
                count = len(visited)
                visited[expr] = count
            stack.pop()
    return visited

def build_node_counts(expr):
    return count_nodes_with_unique_post_traversal(expr)

def build_node_counts2(expr):
    "Build a dict mapping unique Expr node -> unique count."
    i = 0
    e2i = {}

    # Terminals first... (TODO: Not really necessary, but nice, or?)
    for e in traverse_terminals(expr):
        if isinstance(e, UtilityType):
            continue
        if e not in e2i:
            e2i[e] = i
            i += 1

    # ... then the rest
    missed = 0
    for e in unique_post_traversal(expr):
        if isinstance(e, Terminal):
            continue
        if e not in e2i:
            e2i[e] = i
            i += 1
        else:
            missed += 1
    print 'nodes:  ', i
    print 'misses: ', missed

    assert len(e2i) == i
    return e2i

def build_array_from_counts(e2i):
    nv = len(e2i)
    V = object_array(nv)
    for e,i in e2i.iteritems():
        V[i] = e
    return V

def build_node_shapes(V):
    nv = len(V)
    k = 0
    V_shapes = object_array(nv)
    for i,v in enumerate(V):
        # Regular shape
        sh = v.shape()
        # Index "shape"
        idims = v.index_dimensions()
        ish = tuple(idims[idx] for idx in sorted_indices(v.free_indices()))
        # Store "total" shape and size
        tsh = sh + ish
        V_shapes[i] = tsh
        # Count number of elements for CRS representation
        k += len(tsh)

    # Return a more memory efficient CRS representation
    return rows_to_crs(V_shapes, nv, k, int)

def build_node_sizes(V_shapes):
    nv = len(V_shapes)
    V_sizes = int_array(nv)
    for i,sh in enumerate(V_shapes):
        V_sizes[i] = product(sh)
    return V_sizes

def get_node_symbols2(expr, e2i, V_symbols):
    return V_symbols[e2i[expr]]

def map_indexed_symbols(v, e2i, V_symbols):
    # Reuse symbols of arg A for Aii
    Aii = v
    A = Aii.operands()[0]

    # Get symbols of argument A
    A_symbols = get_node_symbols2(A, e2i, V_symbols)

    # Map A_symbols to Aii_symbols
    d = map_indexed_arg_components(Aii)
    symbols = [A_symbols[k] for k in d]
    return symbols

def map_component_tensor_symbols(v, e2i, V_symbols):
    # Reuse symbols of arg Aii for A
    A = v
    Aii = A.operands()[0]

    # Get symbols of argument Aii
    Aii_symbols = get_node_symbols2(Aii, e2i, V_symbols)

    # Map A_symbols to Aii_symbols
    d = map_component_tensor_arg_components(A)
    symbols = [Aii_symbols[k] for k in d]
    return symbols

def map_list_tensor_symbols(v, e2i, V_symbols):
    A = v
    rows = A.operands()

    row_symbols = [get_node_symbols2(row, e2i, V_symbols) for row in rows]

    symbols = []
    for rowsymb in row_symbols:
        symbols.extend(rowsymb) # FIXME: Test that this produces the right transposition
    return symbols

def map_transposed_symbols(v, e2i, V_symbols):
    AT = v
    A, = AT.operands()

    assert not A.free_indices(), "Assuming no free indices in transposed (for now), report as bug if needed." # FIXME
    r, c = A.shape()

    A_symbols = get_node_symbols2(A, e2i, V_symbols)
    assert len(A_symbols) == r*c

    # AT[j,i] = A[i,j]
    # sh(A) = (r,c)
    # sh(AT) = (c,r)
    # AT[j*r+i] = A[i*c+j]
    symbols = [None]*(r*c)
    for j in xrange(c):
        for i in xrange(r):
            symbols[j*r+i] = A_symbols[i*c+j]

    return symbols

def map_variable_symbols(v, e2i, V_symbols):
    # Direct reuse of all symbols
    return get_node_symbols2(v.operands()[0], e2i, V_symbols)

mappable_type = (Indexed, ComponentTensor, ListTensor, Transposed, Variable)
def map_symbols(v, e2i, V_symbols):
    if isinstance(v, Indexed):
        symbols = map_indexed_symbols(v, e2i, V_symbols)
    elif isinstance(v, ComponentTensor):
        symbols = map_component_tensor_symbols(v, e2i, V_symbols)
    elif isinstance(v, ListTensor):
        symbols = map_list_tensor_symbols(v, e2i, V_symbols)
    elif isinstance(v, Transposed):
        symbols = map_transposed_symbols(v, e2i, V_symbols)
    elif isinstance(v, Variable):
        symbols = map_variable_symbols(v, e2i, V_symbols)
    else:
        error("Not a mappable type!")
    return symbols

def build_node_symbols(V, e2i, V_shapes):

    # Compute the total value size for each node, this gives the max number of symbols we need
    V_sizes = build_node_sizes(V_shapes)
    max_symbols = sum(V_sizes)

    # Sparse int matrix for storing variable number of entries (symbols) per row (vertex).
    symbol_type = int
    V_symbols = CRS(len(V), max_symbols, symbol_type)

    # Generator for new symbols with a running counter
    def new_symbols(n):
        a = new_symbols.symbol_count
        b = a + n
        new_symbols.symbol_count = b
        return range(a, b)
    new_symbols.symbol_count = 0

    # For all vertices
    for i,v in enumerate(V):
        n = V_sizes[i]

        if isinstance(v, mappable_type):
            # Map symbols for expressions that only represent a different
            # view of other expressions through shape and indexing mappings.
            symbols = map_symbols(v, e2i, V_symbols)
        elif isinstance(v, FormArgument):
            # Create new symbols for expressions that represent new values
            # TODO: Ignoring symmetries for now, handle by creating only
            # some new symbols and mapping the rest using the symmetry map.
            symbols = new_symbols(n)
        else:
            # Create new symbols for expressions that represent new values
            symbols = new_symbols(n)

        assert len(symbols) == n
        V_symbols.push_row(symbols)

    total_unique_symbols = new_symbols.symbol_count

    assert all(x < total_unique_symbols for x in V_symbols.data)
    assert (total_unique_symbols-1) in V_symbols.data

    return V_symbols, total_unique_symbols

def build_graph_vertices(expr, DEBUG=False):
    # Count unique expression nodes
    e2i = build_node_counts(expr)

    # Make a list of the nodes by their ordering
    V = build_array_from_counts(e2i)

    return e2i, V

def build_graph_symbols(V, e2i, DEBUG):
    # Compute the total shape (value shape x index dimensions) for each node
    V_shapes = build_node_shapes(V)

    # Mark values with symbols
    V_symbols, total_unique_symbols = build_node_symbols(V, e2i, V_shapes)

    return V_shapes, V_symbols, total_unique_symbols

class Graph2(object):
    def __init__(self):
        pass

def build_graph(expr, DEBUG=False):
    # Make empty graph
    G = Graph2()

    # Populate with vertices
    G.e2i, G.V = build_graph_vertices(expr, DEBUG)
    G.nv = len(G.V)

    # Populate with symbols
    G.V_shapes, G.V_symbols, G.total_unique_symbols = build_graph_symbols(G.V, G.e2i, DEBUG)
    if DEBUG: assert G.total_unique_symbols == len(set(G.V_symbols.data))

    # TODO: Generate SSA representation, i.e. scalar ufl expressions

    # TODO: Generate symbol dependencies

    # TODO: What more information to generate?

    return G


def build_ssa(G, DEBUG=False):
    V = G.V

    terminalish = (Terminal, Grad, Restricted)

    for i,v in enumerate(V):
        vsyms = [fixme]
        if isinstance(v, terminalish):
            for j,s in enumerate(vsyms):
                todo = """
                if s -> k exists: continue

                allocate ssa index k:
                k = next ssa index

                store reverse mapping:
                s -> k

                store scalar ufl expression:
                k -> ufl expression for terminal (if scalar) or terminal component j (if nonscalar)
                """
        else:
            for j,s in enumerate(vsyms):
                todo = """
                skip existing values:
                if s -> k exists: continue

                find operand indices:
                kops = [k_op for op in operands]

                compute representation of expression:
                rep = operator
                or
                rep = operator(scalar ufl expression for all k_ops)

                allocate ssa index k:
                k = next ssa index

                store reverse mapping:
                s -> k

                store representation of expression k:
                k -> rep

                store scalar ufl expression:
                k -> ufl expression for operator
                """

    pass 


def find_duplications(G): # FIXME
    vis = {}
    dup = {}
    for i,v in enumerate(G.V):
        for j,s in G.V_symbols:
            pass


def mark_used_symbols(symbols, max_symbol, arg_symbols, initially_used_symbols):
    """TASK: Cover this with tests.

    symbols - array of ints, each int representing a symbol
    max_symbol - an int, one larger than the largest symbol
    arg_symbols - mapping from symbol to symbols or arguments
    initially_used_symbols - sequence of symbols to be marked as used initially
    """

    # Initial state where nothing is marked as used
    used_symbols = int_array(max_symbol)
    num_used = 0

    # Seed with initially used symbols
    for s in initially_used_symbols:
        used_symbols[s] = 1 
        num_used += 1

    # Mark dependencies by looping backwards through symbols array
    for j in xrange(len(symbols)-1,-1,-1):
        s = symbols[j]
        if used_symbols[s]:
            for r in arg_symbols[s]:
                if not used_symbols[r]:
                    used_symbols[r] = 1
                    num_used += 1
                    
    # Return array marking which symbols are used and the number of positives
    return used_symbols, num_used





def rebuild_expression(v, i, G, wops):
    if isinstance(v, Sum):
        return sum(wops)
    if isinstance(v, Product):
        return product(wops)
    if isinstance(v, Power):
        a,b = wops
        return a**b
    return [0 for k in compute_indices(G.V_shapes[i])]

def rebuild_expression_from_graph(G): # FIXME: Implement something like this
    # Regenerate expression via symbols?
    W = object_array(G.total_unique_symbols)
    terminalish = (Terminal, Grad, Restricted)
    for i,v in enumerate(G.V):
        # Find symbols of v
        vs = G.V_symbols[i]

        # Skip if there's nothing new here        
        if all(W[s] is None for s in vs):
            continue

        if isinstance(v, terminalish):
            # Store terminal expression component
            if v.shape() == ():
                j = 0
                s, = vs
                u = v
                W[s] = u
            else:
                for s,c in izip(vs,compute_indices(v.shape())):
                    u = v[c]
                    W[s] = u
        else:
            # Find symbols of operands
            sops = []
            for j, vop in enumerate(v.operands()):
                if isinstance(vop, UtilityType):
                    error("Not expected.")
                    sops.append(()) # TODO: Not sure how to handle this
                else:
                    os = G.V_symbols[G.e2i[vop]]
                    sops.append(os)

            # Store expressions for v symbols
            sh = v.shape()
            if sh == ():
                wops = [W[s[0]] for s in sops]
                w = v.reconstruct(*wops)
                k, = vs
                W[k] = w
            else:
                FIXME
                wops = [tuple(W[k] for k in s) for s in sops]
                w = rebuild_expression(v, i, G, wops)
                for j,k in enumerate(vs):
                    W[k] = w[j]

    # Find symbols of final v
    vs = G.V_symbols[G.nv-1]
    w = [W[k] for k in vs]
    return w


def rebuild_expression(v, i, G, wops):
    if isinstance(v, Sum):
        return sum(wops)
    if isinstance(v, Product):
        return product(wops)
    if isinstance(v, Power):
        a,b = wops
        return a**b
    return [0 for k in compute_indices(G.V_shapes[i])]

def reconstruct_scalar_subexpressions(v, uops): # FIXME FIXME FIXME!!! Implement this as a MultiFunction for all types.
    """
    v is a ufl expression
    uops is a list of expressions
    """
    sh = v.shape()
    if sh == ():
        if isinstance(v, ufl.classes.Sum):
            ops = [op[0] for op in uops]
            return [sum(ops)]
        elif isinstance(v, ufl.classes.Product):
            ops = [op[0] for op in uops]
            return [product(ops)]
        elif isinstance(v, (ufl.classes.Power, ufl.classes.Division)):
            a, b = uops[0][0], uops[1][0]
            return [v.reconstruct(a,b)]
        elif isinstance(v, ufl.classes.MathFunction):
            a = uops[0][0]
            return [v.reconstruct(a)]
        else:
            error("This type not implemented yet: %s." % type(v))
    else:
        error("Tensor valued expressions not implemented here yet!") # FIXME XXX
        return list(compute_indices(sh))

def rebuild_scalar_e2i(G):
    #G.e2i
    #G.V
    #G.V_symbols
    #G.total_unique_symbols

    # Data structures
    ne2i = {}
    NV = object_array(G.total_unique_symbols)
    W = object_array(G.total_unique_symbols)
    terminals = set()

    # Some type groups used below
    indexish = (Indexed, ComponentTensor, ListTensor, Transposed, Variable)
    unexpected = (MultiIndex, Data, Label) + indexish
    terminalish = (Terminal, Grad, Restricted)

    def emit_expression(s, u):
        # Allocate count for scalar expression and
        # store in all cross referenced data structures
        j = ne2i.get(u)
        if j is None:
            j = len(ne2i)
            ne2i[u] = j
            NV[j] = u
        W[s] = u
        print 'emitted', s, j, u

    handled_symbols = int_array(G.total_unique_symbols)
    for i,v in enumerate(G.V):
        # Find symbols of v components
        vs = G.V_symbols[i]

        print ';;;;;;;', i, v, vs

        # Skip if there's nothing new here (should be the case for indexing types)
        if all(handled_symbols[s] for s in vs):
            continue
        #if all(W[s] is not None for s in vs):
        #    continue
        if isinstance(v, unexpected):
            error("Not expecting a %s here!" % type(v))

        for s in vs:
            handled_symbols[s] = 1

        if isinstance(v, terminalish):
            terminals.add(v)
            sh = v.shape()
            if sh == ():
                # Store single terminal expression component
                assert len(vs) == 1
                s, u = vs[0], v
                emit_expression(s, u)
            else:
                # Store each terminal expression component
                for s, c in izip(vs, compute_indices(sh)):
                    u = v[c]
                    emit_expression(s, u)
        else:
            # Find symbols of operands
            sops = []
            for j, vop in enumerate(v.operands()):
                if isinstance(vop, MultiIndex):
                    assert isinstance(v, IndexSum)
                    error("FIXME: Currently not handling IndexSum in here.")
                so = G.V_symbols[G.e2i[vop]]
                sops.append(so)
            # Fetch reconstructed operand expressions
            wops = [tuple(W[k] for k in so) for so in sops]

            # Reconstruct scalar subexpressions of v
            w = reconstruct_scalar_subexpressions(v, wops)
            # Store all scalar subexpressions for v symbols
            for s,u in izip(vs,w):
                emit_expression(s, u)

    # Find symbols of final v
    vs = G.V_symbols[G.nv-1]
    assert all(handled_symbols[s] for s in vs)
    if 0: # DEBUGGING:
        nvs = []
        for s in vs:
            o = W[s]
            print '---', s, o
            nvs.append(ne2i[o])
    else:
        nvs = [ne2i[W[s]] for s in vs] # FIXME: test!

    return ne2i, NV, W, terminals, nvs # FIXME: Which returnees do we need?

def rebuild_expression_from_graph(G): # FIXME: Test me!
    ne2i, NV, W, terminals, nvs = rebuild_scalar_e2i(G)
    # Find expressions of final v
    w = [NV[k] for k in nvs]
    if len(w) == 1:
        return w[0]
    else:
        return as_vector(w) # TODO: Consider shape of initial v
