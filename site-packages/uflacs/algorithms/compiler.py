
from uflacs.utils.tictoc import TicToc
from uflacs.utils.assertions import error

from uflacs.algorithms.graph import build_graph
from uflacs.algorithms.graph_vertices import build_scalar_graph_vertices
from uflacs.algorithms.graph_rebuild import rebuild_scalar_e2i
from uflacs.algorithms.graph_ssa import (compute_dependencies,
                                         mark_active,
                                         mark_partitions,
                                         compute_dependency_count,
                                         invert_dependencies,
                                         default_cache_score_policy,
                                         compute_cache_scores,
                                         allocate_registers)

from uflacs.codeutils.expr_formatter import ExprFormatter
from uflacs.codeutils.element_tensor_formatter import build_loops, format_assignments, format_scaled_additions
from uflacs.codeutils.format_code_structure import format_code_structure, Block

# Hacky flags for enabling printing
profiling = 0

def compile_expression_partitions(expression, argument_mapping):
    # Timing object
    tt = TicToc('compile_expression_partitions')

    # Build the initial coarse computational graph of the expression
    tt.step('build_graph')
    G = build_graph(expression)

    # Build more fine grained computational graph of scalar subexpressions
    tt.step('rebuild_scalar_e2i')
    e2i, NV, W, terminals, nvs = rebuild_scalar_e2i(G, DEBUG=False)
    # Target expression is NV[nvs[:]].

    # Assuming a scalar expression, i.e. only one target symbol
    # TODO: This is good for integrands, but handle nonscalars for expressions!
    if 0: # TODO: Not sure if we need this anymore?
        assert expression.shape() == ()
        assert expression.free_indices() == ()
        assert len(nvs) == 1

    # Straigthen out V to represent single operations
    tt.step('build_scalar_graph_vertices')
    se2i, SV, svs = build_scalar_graph_vertices([NV[s] for s in nvs])

    # Compute sparse dependency matrix
    tt.step('compute_dependencies')
    dependencies = compute_dependencies(se2i, SV)

    # Mark subexpressisons that are actually needed for final result
    tt.step('mark_active')
    max_symbol = len(SV)
    target_variables = svs
    active, num_active = mark_active(max_symbol, dependencies, target_variables)

    # Mark subexpressions with which loop they belong inside
    tt.step('mark_partitions')
    partitions = mark_partitions(SV, active, dependencies, argument_mapping)

    # Count the number of dependencies every subexpr has
    tt.step('compute_dependency_count')
    depcount = compute_dependency_count(dependencies)

    # Build the 'inverse' of the sparse dependency matrix
    tt.step('invert_dependencies')
    inverse_dependencies = invert_dependencies(dependencies, depcount)

    # Use heuristics to mark the usefulness of storing every subexpr in a variable
    tt.step('compute_cache_scores')
    scores = compute_cache_scores(SV,
                                  active,
                                  dependencies,
                                  inverse_dependencies,
                                  partitions,
                                  cache_score_policy=default_cache_score_policy)

    # Allocate variables to store subexpressions in
    tt.step('allocate_registers')
    max_registers = 256 # 8 B * 256 = 4 KB # TODO: Make this a parameter
    score_threshold = 3 # TODO: Make this a parameter
    allocations = allocate_registers(active, partitions, target_variables,
                                     scores, max_registers, score_threshold)
    target_registers = [allocations[r] for r in target_variables]
    num_registers = sum(1 if x >= 0 else 0 for x in allocations)
    # TODO: Could allocate registers for each partition

    # Print timing
    tt.stop()
    if profiling:
        print "Profiling results:"
        print tt

    ir = {}
    ir["num_registers"] = num_registers
    ir["SV"] = SV
    ir["active"] = active
    ir["partitions"] = partitions
    ir["allocations"] = allocations
    ir["target_registers"] = target_registers
    ir["terminals"] = terminals
    return ir

def generate_code_from_ssa(ir, language_formatter):
    # This is a transformer that collects terminal modifiers
    # and delegates formatting to the language_formatter
    expr_formatter = ExprFormatter(language_formatter, {})

    # TODO: Move these to [target_]expr_formatter:
    def format_assignment_statement(lhs, rhs):
        return "%s = %s;" % (lhs, rhs)
    def format_register_variable(p, r):
        return "s[%d]" % (r,) # TODO: Maybe make it "s%d[%d]" % (p, r)

    # Fetch stuff from ir:
    SV = ir["SV"]
    active = ir["active"]
    partitions = ir["partitions"]
    allocations = ir["allocations"]
    target_registers = ir["target_registers"]

    # Find partition range
    min_p = min(partitions)
    max_p = max(partitions)

    # Handle partitions one at a time, in order
    partition_codes = []
    for p in range(min_p, max_p+1):
        code = []
        for i, v in enumerate(SV):
            vreg = allocations[i]
            # Generate assignment code if this expression
            # has an allocated register
            if active[i] and partitions[i] == p and vreg >= 0:
                vname = format_register_variable(p, vreg)
                vcode = expr_formatter.visit(v)
                assignment = format_assignment_statement(vname, vcode)
                code.append(assignment)
                expr_formatter.variables[v] = vname

        partition_codes.append((p,code))

    p = max_p # TODO: Add partitions to target_registers, or is this fine?
    final_variable_names = [format_register_variable(p, r) for r in target_registers]
    return partition_codes, final_variable_names

def generate_expression_body(target_statement_formatter, partition_codes,
                             final_variable_names, num_registers):
    "Join partitions with target specific loops and declarations."
    # Use shorter name below
    tfmt = target_statement_formatter
    dh = target_statement_formatter._dependency_handler

    # Make a shallow copy of dict, we consume the dict entries below
    partition_codes = dict(partition_codes)

    # Both 'required' and 'terminals' are filled during partition compilation
    #req = dh.required
    #term = dh.terminals

    # Build loop structure (intended for tabulate_tensor)
    loops = []
    definitions = []
    partitions = []

    def update_loops(loop, defs, p):
        loops.append(loop)
        definitions.append(defs)
        partitions.append(partition_codes.get(p,""))
        if p in partition_codes:
            del partition_codes[p]

    # TODO: This partition numbering is maybe too "magic"?
    # --- Partition 0: independent of x and arguments.
    p = 0
    if 1:
        piecewise_defs = []
        piecewise_defs += tfmt.define_output_variables_reset()
        piecewise_defs += tfmt.define_piecewise_geometry()
        piecewise_defs += tfmt.define_piecewise_coefficients()
        # TODO: Make registers separately for each partition level?
        if num_registers:
            piecewise_defs += tfmt.define_registers(num_registers)
        piecewise_defs += [""]
        update_loops(None, piecewise_defs, p)

    # --- Partition 1: x dependency
    # FIXME: Separate cleanly between:
    # - x assumed known
    # - xi assumed known
    # - xi defined by inserted quadrature loop
    # - x defined by inserted quadrature loop
    # ... Probably best to configure tfmt to know this beforehand some place?
    p = 1
    if 1:
        coord_loop = tfmt.define_coord_loop() # Can be None
        coord_dependent_defs = []
        coord_dependent_defs += tfmt.define_coord_vars()
        coord_dependent_defs += tfmt.define_coord_dependent_geometry()
        update_loops(coord_loop, coord_dependent_defs, p)

    # --- Partition 2: coord and coefficient dependency
    p = 2
    if 1:
        w_dependent_defs = []
        w_dependent_defs += tfmt.define_coord_dependent_coefficients()
        update_loops(None, w_dependent_defs, p)

    # --- Partitions 3...3+rank-1: argument function dependency
    rank = len(dh.arguments)
    for p in range(3,3+rank):
        ac = 2+rank-p # Magic formula for mapping partition to argument count
        update_loops(tfmt.define_argument_for_loop(ac),
                     tfmt.define_argument_loop_vars(ac),
                     p)

    # --- Final partition: final assignments
    p = 3 + rank
    if 1:
        assign_to_variables = tfmt.output_variable_names(len(final_variable_names))
        scaling_factor = tfmt.accumulation_scaling_factor()
        if scaling_factor is None:
            final_statements = list(format_assignments(zip(assign_to_variables,
                                                           final_variable_names)))
        else:
            final_statements = list(format_scaled_additions(zip(assign_to_variables,
                                                                final_variable_names),
                                                            scaling_factor))
        update_loops(None, final_statements, p)

    # --- Should be nothing left now
    assert not partition_codes

    # Stitch it together
    code = build_loops(loops, definitions, partitions)

    return code

