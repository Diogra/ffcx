
import ufl
from ufl.classes import (Terminal, UtilityType, FormArgument, Argument,
                         Grad, Restricted, Indexed)
from ufl.algorithms import expand_derivatives, expand_compounds

from uflacs.utils.tictoc import TicToc
from uflacs.utils.assertions import error
from uflacs.codeutils.format_code_structure import format_code_structure, Block
from uflacs.codeutils.expr_formatter import ExprFormatter

from uflacs.codeutils.target_formatter import DependencyHandler, CppLanguageFormatter, CppStatementFormatter

from uflacs.codeutils.element_tensor_formatter import (build_loops,
                                                       format_assignments,
                                                       format_additions,
                                                       format_scaled_assignments,
                                                       format_scaled_additions)

from uflacs.algorithms.datastructures import int_array, object_array
from uflacs.algorithms.graph import build_graph
from uflacs.algorithms.graph_vertices import build_scalar_graph_vertices
from uflacs.algorithms.graph_rebuild import rebuild_scalar_e2i
from uflacs.algorithms.graph_ssa import (compute_dependencies,
                                         mark_active,
                                         mark_partitions,
                                         compute_dependency_count,
                                         invert_dependencies,
                                         default_cache_score_policy,
                                         compute_cache_scores,
                                         allocate_registers)

# Hacky flags for enabling printing
debug = 0
profiling = 0

def compile_element(element, prefix): # Makes no sense in here really
    return "// TODO: Compile element %s" % str(element)

def generate_code_from_ssa(SV, active, partitions, allocations,
                           target_registers, expr_formatter):
    terminalish = (Terminal, Grad, Restricted, Indexed)
    min_p = min(partitions)
    max_p = max(partitions)

    # TODO: Move these to [target_]expr_formatter:
    def format_assignment_statement(lhs, rhs):
        return "%s = %s;" % (lhs, rhs)
    def format_register_variable(p, r):
        return "s[%d]" % (r,) # TODO: Maybe make it "s%d[%d]" % (p, r)

    # Handle partitions one at a time, in order
    partition_codes = []
    for p in range(min_p, max_p+1):
        code = []
        for i, v in enumerate(SV):
            vreg = allocations[i]
            # Generate assignment code if this expression
            # has an allocated register
            if active[i] and partitions[i] == p and vreg >= 0:
                vname = format_register_variable(p, vreg)
                vcode = expr_formatter.visit(v)
                assignment = format_assignment_statement(vname, vcode)
                code.append(assignment)
                expr_formatter.variables[v] = vname

        partition_codes.append((p,code))

    p = max_p # TODO: Add partitions to target_registers, or is this fine?
    final_variable_names = [format_register_variable(p, r) for r in target_registers]
    return partition_codes, final_variable_names

def compile_expression_partitions(expression, argument_mapping):
    # Timing object
    tt = TicToc('compile_expression_partitions')

    # Build the initial coarse computational graph of the expression
    tt.step('build_graph')
    G = build_graph(expression)

    # Build more fine grained computational graph of scalar subexpressions
    tt.step('rebuild_scalar_e2i')
    e2i, NV, W, terminals, nvs = rebuild_scalar_e2i(G, DEBUG=False)
    # Target expression is NV[nvs[:]].

    # Assuming a scalar expression, i.e. only one target symbol
    # TODO: This is good for integrands, but handle nonscalars for expressions!
    if 0: # TODO: Not sure if we need this anymore?
        assert expression.shape() == ()
        assert expression.free_indices() == ()
        assert len(nvs) == 1

    # Straigthen out V to represent single operations
    tt.step('build_scalar_graph_vertices')
    se2i, SV, svs = build_scalar_graph_vertices([NV[s] for s in nvs])

    # Compute sparse dependency matrix
    tt.step('compute_dependencies')
    dependencies = compute_dependencies(se2i, SV)

    # Mark subexpressisons that are actually needed for final result
    tt.step('mark_active')
    max_symbol = len(SV)
    target_variables = svs
    active, num_active = mark_active(max_symbol, dependencies, target_variables)

    # Mark subexpressions with which loop they belong inside
    tt.step('mark_partitions')
    partitions = mark_partitions(SV, active, dependencies, argument_mapping)

    # Count the number of dependencies every subexpr has
    tt.step('compute_dependency_count')
    depcount = compute_dependency_count(dependencies)

    # Build the 'inverse' of the sparse dependency matrix
    tt.step('invert_dependencies')
    inverse_dependencies = invert_dependencies(dependencies, depcount)

    # Use heuristics to mark the usefulness of storing every subexpr in a variable
    tt.step('compute_cache_scores')
    scores = compute_cache_scores(SV,
                                  active,
                                  dependencies,
                                  inverse_dependencies,
                                  partitions,
                                  cache_score_policy=default_cache_score_policy)

    # Allocate variables to store subexpressions in
    tt.step('allocate_registers')
    max_registers = 256 # 8 B * 256 = 4 KB # TODO: Make this a parameter
    score_threshold = 3 # TODO: Make this a parameter
    allocations = allocate_registers(active, partitions, target_variables,
                                     scores, max_registers, score_threshold)
    target_registers = [allocations[r] for r in target_variables]
    num_registers = sum(1 if x >= 0 else 0 for x in allocations)
    # TODO: Could allocate registers for each partition

    # Print timing
    tt.stop()
    if profiling:
        print tt

    return (num_registers, SV, active, partitions, allocations,
            target_registers, terminals)

def compile_expression_body(expr, language_formatter, statement_formatter):
    argument_mapping = dict((k,v) for (k,v)
                            in language_formatter._form_argument_mapping.items()
                            if isinstance(k, Argument))

    # Compile expression into partitioned code listings
    ir = compute_expression_body_ir(expr, argument_mapping)
    code = generate_expression_body_code(ir, language_formatter, statement_formatter)
    return code

# TODO: Refactoring!
def compute_expression_body_ir(expr, argument_mapping):
    (num_registers, SV, active, partitions, allocations,
     target_registers, terminals) =\
                     compile_expression_partitions(expr, argument_mapping)
    ir = {}
    ir["num_registers"] = num_registers
    ir["SV"] = SV
    ir["active"] = active
    ir["partitions"] = partitions
    ir["allocations"] = allocations
    ir["target_registers"] = target_registers
    ir["terminals"] = terminals
    return ir

def generate_expression_body_code(ir, language_formatter, statement_formatter):
    # Pass set of needed terminal expressions to the dependency handler
    statement_formatter._dependency_handler.update_terminals(ir["terminals"])

    # This is a transformer that collects terminal modifiers
    # and delegates formatting to the language_formatter
    expr_formatter = ExprFormatter(language_formatter, {})

    # TODO: Describe stages better and refactor as needed
    # Generate pieces of code for expressions
    #tt.step('generating code')
    partition_codes, final_variable_names = generate_code_from_ssa(
        ir["SV"],
        ir["active"],
        ir["partitions"],
        ir["allocations"],
        ir["target_registers"],
        expr_formatter)

    # Generate full code
    code = generate_expression_body(statement_formatter,
                                    partition_codes,
                                    final_variable_names,
                                    ir["num_registers"])
    return code

def generate_expression_body(target_statement_formatter, partition_codes,
                             final_variable_names, num_registers):
    "Join partitions with target specific loops and declarations."
    # Use shorter name below
    tfmt = target_statement_formatter
    dh = target_statement_formatter._dependency_handler

    # Make a shallow copy of dict, we consume the dict entries below
    partition_codes = dict(partition_codes)

    # Both 'required' and 'terminals' are filled during partition compilation
    #req = dh.required
    #term = dh.terminals

    # Build loop structure (intended for tabulate_tensor)
    loops = []
    definitions = []
    partitions = []

    def update_loops(loop, defs, p):
        loops.append(loop)
        definitions.append(defs)
        partitions.append(partition_codes.get(p,""))
        if p in partition_codes:
            del partition_codes[p]

    # TODO: This partition numbering is maybe too "magic"?
    # --- Partition 0: independent of x and arguments.
    p = 0
    if 1:
        piecewise_defs = []
        piecewise_defs += tfmt.define_piecewise_geometry()
        piecewise_defs += tfmt.define_piecewise_coefficients()
        # TODO: Make registers separately for each partition level?
        if num_registers:
            piecewise_defs += tfmt.define_registers(num_registers)
        update_loops(None, piecewise_defs, p)

    # --- Partition 1: x dependency
    # FIXME: Separate cleanly between:
    # - x assumed known
    # - xi assumed known
    # - xi defined by inserted quadrature loop
    # - x defined by inserted quadrature loop
    # ... Probably best to configure tfmt to know this beforehand some place?
    p = 1
    if 1:
        coord_loop = tfmt.define_coord_loop() # Can be None
        coord_dependent_defs = []
        coord_dependent_defs += tfmt.define_coord_vars()
        coord_dependent_defs += tfmt.define_coord_dependent_geometry()
        update_loops(coord_loop, coord_dependent_defs, p)

    # --- Partition 2: coord and coefficient dependency
    p = 2
    if 1:
        w_dependent_defs = []
        w_dependent_defs += tfmt.define_coord_dependent_coefficients()
        update_loops(None, w_dependent_defs, p)

    # --- Partitions 3...3+rank-1: argument function dependency
    rank = len(dh.arguments)
    for p in range(3,3+rank):
        ac = 2+rank-p # Magic formula for mapping partition to argument count
        update_loops(tfmt.define_argument_for_loop(ac),
                     tfmt.define_argument_loop_vars(ac),
                     p)

    # --- Final partition: final assignments
    p = 3 + rank
    if 1:
        assign_to_variables = tfmt.output_variable_names(len(final_variable_names))
        scaling_factor = tfmt.accumulation_scaling_factor()
        if scaling_factor is None:
            final_statements = list(format_assignments(zip(assign_to_variables,
                                                           final_variable_names)))
        else:
            final_statements = list(format_scaled_additions(zip(assign_to_variables,
                                                                final_variable_names),
                                                            scaling_factor))
        update_loops(None, final_statements, p)

    # --- Should be nothing left now
    if partition_codes:
        if debug:
            print '------------------- partition_codes:'
            print partition_codes
            print '-------------------'
    assert not partition_codes

    # Stitch it together
    code = build_loops(loops, definitions, partitions)

    return code

def compile_expression(expr, prefix=""):
    expr = expand_compounds(expr)
    expr = expand_derivatives(expr,
                              apply_expand_compounds_before=False,
                              apply_expand_compounds_after=False,
                              use_alternative_wrapper_algorithm=False)

    # TODO: Use preprocessing, get from expr data:
    object_names = {}
    form_argument_mapping = {}

    dependency_handler = DependencyHandler(object_names)

    # This formatter is a multifunction implementing target specific formatting rules
    language_formatter = CppLanguageFormatter(dependency_handler,
                                              form_argument_mapping)

    # TODO: Also needs to know about (lack of) integration context:
    cell = expr.cell()
    statement_formatter = CppStatementFormatter(dependency_handler, cell)

    code = compile_expression_body(expr, language_formatter, statement_formatter)

    formatted = format_code_structure(Block(code))
    return formatted

def compile_form(form, prefix=""):
    tt = TicToc("compile_form")

    # Preprocess form
    tt.step('preprocess')
    form_data = form.compute_form_data()

    # We'll place all code in a list while building the program
    code = []

    # Generate code for each integral
    k = 0
    for ida in form_data.integral_data:
        for integral in ida.integrals:
            integrand = integral.integrand()

            tt.step('compile_expression_body for integral %d' % k); k += 1

            # Reconstructing default formatter for each integral to reset state
            dependency_handler = DependencyHandler(form_data.object_names)

            # This formatter is a multifunction implementing target specific formatting rules
            language_formatter = CppLanguageFormatter(dependency_handler, form_data.function_replace_map)

            # FIXME: Also needs to know about integration context:
            statement_formatter = CppStatementFormatter(dependency_handler, form_data.cell)

            # Use generic compiler routine to compile expression body
            integral_code = compile_expression_body(integrand, language_formatter, statement_formatter)

            # Wrap in a block for readability (this is not fully compilable code though)
            code.append(['',Block(integral_code),''])

    tt.step('format_code_structure')
    formatted = format_code_structure(code)

    tt.stop()
    if profiling:
        print tt

    return formatted
